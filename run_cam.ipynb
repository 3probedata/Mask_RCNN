{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "ROOT:  D:\\Project\\Mask_RCNN\n",
      "D:\\Project\\Mask_RCNN\\logs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import imutils\n",
    "import numpy as np\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import utils, visualize\n",
    "from imutils.video import WebcamVideoStream\n",
    "import random\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import datetime\n",
    "\n",
    "# Root directory of the project\n",
    "from samples.coco.coco import CocoConfig\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "\n",
    "out_filename = '' # video output file name\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "print(MODEL_DIR)\n",
    "#video_input = \"D:/Project/yolov4/Mango1/data/data/2019_tw_run.mp4\" #\"video source. If video_input=0, uses webcam 0 stream\"\n",
    "video_input = 0 #usb cam device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Project\\Mask_RCNN\\mask_rcnn_coco.h5\n",
      "\n",
      "Configurations:\n",
      "AUGMENT                        False\n",
      "AUGMENTATION                   False\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  448\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  384\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [448 448   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "config                         <configparser.ConfigParser object at 0x00000261FB83A788>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "print(COCO_MODEL_PATH)\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "\n",
    "class InferenceConfig(CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_MIN_DIM = 384\n",
    "    IMAGE_MAX_DIM = 448\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SCREEN_NAME = 'Mask RCNN LIVE'\n",
    "#cv2.namedWindow(SCREEN_NAME, cv2.WINDOW_NORMAL)\n",
    "#cv2.setWindowProperty(SCREEN_NAME, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "#width = config.IMAGE_MAX_DIM\n",
    "#height = config.IMAGE_MIN_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapVideo(frame):\n",
    "\n",
    "    #if SHOW_FPS_WO_COUNTER:\n",
    "    start_time = time.time()  # start time of the loop\n",
    "\n",
    "    if PROCESS_IMG:\n",
    "        results = model.detect([frame])\n",
    "        r = results[0]\n",
    "\n",
    "        # Run detection\n",
    "        masked_image = visualize.display_instances_10fps(frame, r['rois'], r['masks'],\n",
    "                                                         r['class_ids'], class_names, r['scores'], colors=colors,\n",
    "                                                         real_time=True)\n",
    "\n",
    "    if PROCESS_IMG:\n",
    "        s = masked_image\n",
    "    else:\n",
    "        s = frame\n",
    "    # print(\"Image shape: {1}x{0}\".format(s.shape[0], s.shape[1]))\n",
    "\n",
    "    width = s.shape[1]\n",
    "    height = s.shape[0]\n",
    "    top_left_corner = (width - 120, height - 20)\n",
    "    bott_right_corner = (width, height)\n",
    "    top_left_corner_cvtext = (width - 80, height - 5)\n",
    "\n",
    "    if SHOW_FPS:\n",
    "        fps_counter += 1\n",
    "        if (time.time() - start_time) > 5:  # every 5 second\n",
    "            fps_caption = \"FPS: {:.0f}\".format(fps_counter / (time.time() - start_time))\n",
    "            # print(fps_caption)\n",
    "            fps_counter = 0\n",
    "            start_time = time.time()\n",
    "        ret, baseline = cv2.getTextSize(fps_caption, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(s, (width - ret[0], height - ret[1] - baseline), bott_right_corner, gentle_grey, -1)\n",
    "        cv2.putText(s, fps_caption, (width - ret[0], height - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, white,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "\n",
    "    if SHOW_FPS_WO_COUNTER:\n",
    "        # Display the resulting frame\n",
    "        fps_caption = \"FPS: {:.0f}\".format(1.0 / (time.time() - start_time))\n",
    "        # print(\"FPS: \", 1.0 / (time.time() - start_time))\n",
    "\n",
    "        # Put the rectangle and text on the bottom left corner\n",
    "        ret, baseline = cv2.getTextSize(fps_caption, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(s, (width - ret[0], height - ret[1] - baseline), bott_right_corner, gentle_grey, -1)\n",
    "        cv2.putText(s, fps_caption, (width - ret[0], height - baseline),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, white, 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    s = cv2.resize(s, (640, 480))\n",
    "\n",
    "    return SCREEN_NAME, s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGet:\n",
    "    \"\"\"\n",
    "    Class that continuously gets frames from a VideoCapture object\n",
    "    with a dedicated thread.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src + cv2.CAP_DSHOW)\n",
    "        #self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "        \n",
    "    def start(self):    \n",
    "        Thread(target=self.get, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def get(self):\n",
    "        while not self.stopped:\n",
    "            if not self.grabbed:\n",
    "                self.stop()\n",
    "            else:\n",
    "                (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threadVideoGet(source=0):\n",
    "    \"\"\"\n",
    "    Dedicated thread for grabbing video frames with VideoGet object.\n",
    "    Main thread shows video frames.\n",
    "    \"\"\"\n",
    "\n",
    "    video_getter = VideoGet(source).start()\n",
    "    #cps = CountsPerSec().start()\n",
    "\n",
    "    while True:\n",
    "        if (cv2.waitKey(1) == ord(\"q\")) or video_getter.stopped:\n",
    "            video_getter.stop()\n",
    "            break\n",
    "\n",
    "        frame = video_getter.frame\n",
    "        name, frame = CapVideo(frame)\n",
    "\n",
    "        cv2.imshow(name, frame)\n",
    "        #cps.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    }
   ],
   "source": [
    "# Create model object in inference mode.\n",
    "global model\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "colors = visualize.random_colors(len(class_names))\n",
    "\n",
    "gentle_grey = (45, 65, 79)\n",
    "white = (255, 255, 255)\n",
    "\n",
    "OPTIMIZE_CAM = False\n",
    "SHOW_FPS = False\n",
    "SHOW_FPS_WO_COUNTER = True  # faster\n",
    "PROCESS_IMG = True\n",
    "\n",
    "#if OPTIMIZE_CAM:\n",
    "#    vs = WebcamVideoStream(src=0).start()\n",
    "\n",
    "if SHOW_FPS:\n",
    "    fps_caption = \"FPS: 0\"\n",
    "    global fps_counter\n",
    "    fps_counter = 0\n",
    "    global start_time\n",
    "    start_time = time.time()\n",
    "\n",
    "threadVideoGet(video_input)\n",
    "video_getter = VideoGet(video_input).start()\n",
    "video_getter.stop()\n",
    "video_getter.stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "a = tf.constant(1.)\n",
    "b = tf.constant(2.)\n",
    "print(a+b)\n",
    "print(tf.__version__)\n",
    "print('GPU:', tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "print(gpus, cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
